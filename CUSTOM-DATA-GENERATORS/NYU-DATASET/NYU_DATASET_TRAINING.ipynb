{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NYU-DATASET-TRAINING.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC6QEUI5kok1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "a9b70198-bd9a-4d6c-d503-e9a1a0f13a91"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # kernel\n",
        "        # (32-5/1)+1 = ouput of each filter\n",
        "        # output all filters = 28 x92 = 2576 \n",
        "        self.conv1 = nn.Conv3d(1,96,(5,5,5), padding=0)\n",
        "        self.pool  = nn.MaxPool3d(2, stride=2)\n",
        "        # you can use this formula [(Wâˆ’K+2P)/S]+1.\n",
        "        self.conv2  =  nn.Conv3d(96,192,(3,3,3), padding=0)\n",
        "        self.pool1  =  nn.MaxPool3d(2, stride=2)\n",
        "        self.conv3  =  nn.Conv3d(192,384,(3,3,3), padding=0)\n",
        "        self.pool2  =  nn.MaxPool3d(2, stride=2)\n",
        "        \n",
        "        self.ln1    =  nn.Linear(in_features=3072, out_features=4096)\n",
        "        \n",
        "   #     self.bn1 = nn.BatchNorm1d(num_features=4096)\n",
        "\n",
        "        self.ln2    =  nn.Linear(in_features=4096, out_features=1024)\n",
        "\n",
        " #       self.bn2 = nn.BatchNorm1d(num_features=1024)\n",
        " #       self.lstm1  = nn.LSTM(1024, 1024, 36)\n",
        " \n",
        "        self.out1    =  nn.Linear(in_features=1024, out_features=14)\n",
        "\n",
        "  #     self.softmax_x = nn.Softmax()\n",
        "  #     self.out2    =  nn.Linear(in_features=1024, out_features=36)        \n",
        "  #     self.softmax_y = nn.Softmax()\n",
        "  #     self.out3    =  nn.Linear(in_features=1024, out_features=36)        \n",
        "  #     self.softmax_z = nn.Softmax()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(-1, 3072)\n",
        "\n",
        "        x = self.ln1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "  #      x = self.bn1(x)\n",
        "        \n",
        "       \n",
        "        x = self.ln2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "  #      x = self.lstm1(x)\n",
        "        \n",
        " #       x = self.bn2(x)\n",
        "\n",
        "        x1 = self.out1(x)\n",
        "  #      x1 = self.softmax_x(x1)# ,Dim =1)\n",
        "\n",
        " #       x2 = self.out2(x)\n",
        " #       x2 = self.softmax_y(x2)# ,Dim =1)\n",
        "\n",
        " #       x3 = self.out3(x)\n",
        " #       x3 = self.softmax_z(x3)# ,Dim =1\n",
        "\n",
        " #       a = torch.cat((x1,x2,x3),dim=0)\n",
        "        ret = x1.view(-1, 14)\n",
        "         \n",
        "        return ret\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        x = self.x\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features    \n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "net = Net()\n",
        "print(net)\n",
        "\n",
        "net.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv3d(1, 96, kernel_size=(5, 5, 5), stride=(1, 1, 1))\n",
            "  (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
            "  (pool1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv3d(192, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
            "  (pool2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (ln1): Linear(in_features=3072, out_features=4096, bias=True)\n",
            "  (ln2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (out1): Linear(in_features=1024, out_features=14, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv3d(1, 96, kernel_size=(5, 5, 5), stride=(1, 1, 1))\n",
              "  (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
              "  (pool1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv3d(192, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
              "  (pool2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (ln1): Linear(in_features=3072, out_features=4096, bias=True)\n",
              "  (ln2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "  (out1): Linear(in_features=1024, out_features=14, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa3HLbbElxjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator():\n",
        "    def __init__(self):\n",
        "      #  pass\n",
        "        import numpy as np\n",
        "        import pandas as pd\n",
        "        import h5py\n",
        "        self.NYU_X = pd.read_csv('/content/drive/My Drive/FYP data/nyu dataset/pca_labeled file _1/NEW_RELATIONAL_PCA/14_POINT_RELATION_FILE.csv')\n",
        " #       self.NYU_Y = pd.read_csv('/content/joint_y.csv')\n",
        " #       self.NYU_Z = pd.read_csv('/content/joint_z.csv')\n",
        "        #############################################################################################################\n",
        " \n",
        "\n",
        "    def get_data(self,file_no):\n",
        "        import h5py\n",
        "        import numpy as np                     \n",
        "\n",
        "        filename = '/content/TSDF/'+str(file_no)+'.h5'\n",
        "           # getting 3d input from h5 files\n",
        "        h5 = h5py.File(filename,'r')\n",
        "        input = np.array(h5['TSDF'])\n",
        "        input = np.reshape(input,(1,1,32,32,32))\n",
        "                # VSTOXX futures data\n",
        "        h5.close()           \n",
        "        inputs = np.array(input).tolist()\n",
        "        inputs = torch.FloatTensor(inputs)\n",
        "\n",
        "        output1 = self.NYU_X.iloc[file_no].values\n",
        " #       output2 = self.NYU_Y.iloc[file_no].values\n",
        " #       output3 = self.NYU_Z.iloc[file_no].values\n",
        "                                                                       \n",
        "\n",
        "        output1 = output1[0:14]\n",
        "  #      output2 = output1[10:20]\n",
        "  #      output3 = output1[20:36]\n",
        "\n",
        "        output1 = np.asarray(output1)\n",
        "   #     output2 = np.asarray(output2)\n",
        "    #    output3 = np.asarray(output3)\n",
        "  #      output  = np.append( output1,output2)\n",
        "  #      output  = np.append(output,output3)\n",
        "  #      output  = np.reshape(output1,(-1,36))\n",
        "        output  = torch.from_numpy(output1).float()\n",
        "        output  = torch.reshape(output, (1, 14))\n",
        "\n",
        "        return inputs,output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUyBxLn8l5Nz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "33be79f8-0144-413e-afc8-4b297452b290"
      },
      "source": [
        "gen = Generator()\n",
        "net = Net()\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import numpy \n",
        "\n",
        "inputs , labels = gen.get_data(1126)\n",
        "#inputs = np.random.rand(1,1,32,32,32)\n",
        "print(labels)\n",
        "print(np.shape(labels))\n",
        "#inputs = inputs.detach().numpy()\n",
        "#inputs = torch.from_numpy(inputs).float()\n",
        "\n",
        "outputs = net(inputs)\n",
        "print(np.shape(outputs))\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.5553,  0.2882, -0.3079, -0.1309, -0.0493,  0.1058, -0.1873,  0.3007,\n",
            "         -0.0166, -0.1716, -0.0343, -0.0783,  0.2015, -0.1207]])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 14])\n",
            "tensor([[ 0.0336,  0.0046,  0.0010, -0.0253, -0.0116,  0.0005, -0.0092,  0.0243,\n",
            "         -0.0214,  0.0039,  0.0033,  0.0057,  0.0407,  0.0396]],\n",
            "       grad_fn=<ViewBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5hdNdDgl52H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.L1Loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flvSK7kImxQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "outputId": "6c48cb0a-f52d-48fd-f35c-3929f8e51407"
      },
      "source": [
        "########################################\n",
        "######## GETS 10 FILES IN A ROW\n",
        "net = Net()\n",
        "net.to(device)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import numpy\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "#optimizer = optim.Adam(net.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.0005, amsgrad=False)\n",
        "\n",
        "gen = Generator()\n",
        "import random\n",
        "\n",
        "for epoch in range(1,30):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    i = 0\n",
        "    if epoch  == 5:\n",
        "      for g in optimizer.param_groups:\n",
        "           g['lr'] = 0.001\n",
        "    if epoch == 10:\n",
        "       for g in optimizer.param_groups:\n",
        "           g['lr'] = 0.0001\n",
        " #   if epoch == 15:\n",
        " #     for g in optimizer.param_groups:\n",
        "#           g['lr'] = 0.00001\n",
        "\n",
        "    for i in range(0,3500):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        k=0\n",
        "        file_no = random.randint(0, 60000)\n",
        "        for k in range (0,16):\n",
        "            file_no = file_no + 1\n",
        "            if k == 0 :\n",
        "                  inputs, labels = gen.get_data(file_no)\n",
        "            if k > 0 :      \n",
        "                  inputs_stack, labels_stack = gen.get_data(file_no)\n",
        "                  inputs = torch.cat([inputs, inputs_stack])\n",
        "                  labels = torch.cat([labels, labels_stack])\n",
        "\n",
        "\n",
        "        \n",
        "        INN = inputs.to(device)\n",
        "        OUT = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(INN)\n",
        "        loss = criterion(outputs, OUT)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        LOSS = 0.0\n",
        "        if i == 3499:    # print every 2000 mini-batches# CHANGE THIS VALUE\n",
        "            print('[%d, %5d] loss: %.5f' %\n",
        "                  (epoch , i + 1, running_loss / 3500))\n",
        "            running_loss = 0.0\n",
        "            \n",
        "            g = 0\n",
        "            for g in range(0,750):\n",
        "                        k=0\n",
        "                        file_no = random.randint(60012, 72730)\n",
        "                        for k in range (0,16):\n",
        "                            file_no = file_no + 1\n",
        "                            if k == 0 :\n",
        "                                    inputs, labels = gen.get_data(file_no)\n",
        "                            if k > 0 :      \n",
        "                                    inputs_stack, labels_stack = gen.get_data(file_no)\n",
        "                                    inputs = torch.cat([inputs, inputs_stack])\n",
        "                                    labels = torch.cat([labels, labels_stack])\n",
        " \n",
        "                  \n",
        "\n",
        "                 \n",
        "\n",
        "                 \n",
        "\n",
        "                        INN = inputs.to(device)\n",
        "                        OUT = labels.to(device)\n",
        "           # zero the parameter gradients\n",
        "                        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "                        outputs = net(INN)\n",
        "                        loss = criterion(outputs, OUT)\n",
        "       #    loss = criterion(outputs, labels)\n",
        "                        LOSS  += loss.item()\n",
        "            LOSS = LOSS/750\n",
        "            print('Avergae_validation_loss was='+str(LOSS) )\n",
        "            running_loss = 0.0\n",
        "            if epoch ==1 :\n",
        "                best_loss = LOSS\n",
        "                torch.save(net, '/content/drive/My Drive/FYP data/models/model1/'+str('pca_14_points_relational.pt'))\n",
        "            if LOSS < best_loss:\n",
        "                best_loss = LOSS\n",
        "                torch.save(net, '/content/drive/My Drive/FYP data/models/model1/'+str('pca_14_points_relational.pt'))\n",
        "    \n",
        "            LOSS = 0    \n",
        "            running_loss = 0.0   \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  3500] loss: 0.18680\n",
            "Avergae_validation_loss was=0.1579167726089557\n",
            "[2,  3500] loss: 0.12151\n",
            "Avergae_validation_loss was=0.14431485202908517\n",
            "[3,  3500] loss: 0.09802\n",
            "Avergae_validation_loss was=0.12172666262338559\n",
            "[4,  3500] loss: 0.08236\n",
            "Avergae_validation_loss was=0.11796152352044979\n",
            "[5,  3500] loss: 0.05891\n",
            "Avergae_validation_loss was=0.10530021015306314\n",
            "[6,  3500] loss: 0.05407\n",
            "Avergae_validation_loss was=0.10542824666202068\n",
            "[7,  3500] loss: 0.04876\n",
            "Avergae_validation_loss was=0.0977306349799037\n",
            "[8,  3500] loss: 0.04747\n",
            "Avergae_validation_loss was=0.10070751164729397\n",
            "[9,  3500] loss: 0.04522\n",
            "Avergae_validation_loss was=0.09523541676749786\n",
            "[10,  3500] loss: 0.04286\n",
            "Avergae_validation_loss was=0.10205675203601519\n",
            "[11,  3500] loss: 0.04215\n",
            "Avergae_validation_loss was=0.09277909583350023\n",
            "[12,  3500] loss: 0.04259\n",
            "Avergae_validation_loss was=0.0981282900000612\n",
            "[13,  3500] loss: 0.04057\n",
            "Avergae_validation_loss was=0.09529716619228323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-785108e0c8d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                   \u001b[0minputs_stack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_stack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                   \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_stack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-e121a02f76c3>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, file_no)\u001b[0m\n\u001b[1;32m     18\u001b[0m            \u001b[0;31m# getting 3d input from h5 files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mh5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TSDF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;31m# VSTOXX futures data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mread_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAugThWO0Rfp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "37da7c26-f8da-427a-dbe8-4688263bf1bf"
      },
      "source": [
        "net = Net()\n",
        "net.to(device)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import numpy\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "\n",
        "gen = Generator()\n",
        "import random\n",
        "\n",
        "for epoch in range(1,30):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    i = 0\n",
        "    for i in range(0, 3500):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        k=0\n",
        "        file_no = random.randint(0, 60000)\n",
        "        for k in range (0,16):\n",
        "            file_no = file_no + 1\n",
        "            if k == 0 :\n",
        "                  inputs, labels = gen.get_data(file_no)\n",
        "            if k > 0 :      \n",
        "                  inputs_stack, labels_stack = gen.get_data(file_no)\n",
        "                  inputs = torch.cat([inputs, inputs_stack])\n",
        "                  labels = torch.cat([labels, labels_stack])\n",
        "\n",
        "        INN = inputs.to(device)\n",
        "        OUT = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(INN)\n",
        "        loss = criterion(outputs, OUT)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i == 3499:    # print every 2000 mini-batches# CHANGE THIS VALUE\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch , i + 1, running_loss / 3500))\n",
        "            running_loss = 0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,  3500] loss: 0.362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-637dd2aee692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                   \u001b[0minputs_stack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_stack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                   \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_stack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-93bb6bc6dfae>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, file_no)\u001b[0m\n\u001b[1;32m     18\u001b[0m            \u001b[0;31m# getting 3d input from h5 files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mh5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TSDF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;31m# VSTOXX futures data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mread_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mwFz5aJm05R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import numpy\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "\n",
        "gen = Generator()\n",
        "import random\n",
        "\n",
        "for epoch in range(1,30):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    i = 0\n",
        "    for i in range(0, 261):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        k=0\n",
        "        for k in range (0,5):\n",
        "              file_no = random.randint(0, 60000)\n",
        "              random_or_counting = random.randint(0, 1)\n",
        "              dataset_no = random.randint(1, 6)\n",
        "              if k == 0 :\n",
        "                         inputs, labels = gen.get_data(file_no,random_or_counting,dataset_no)\n",
        "              if k > 0 :      \n",
        "                         inputs_stack, labels_stack = gen.get_data(file_no,random_or_counting,dataset_no)\n",
        "                         inputs = torch.cat([inputs, inputs_stack])\n",
        "                         labels = torch.cat([labels, labels_stack])\n",
        "\n",
        "\n",
        "\n",
        "        INN = inputs.to(device)\n",
        "        OUT = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(INN)\n",
        "        loss = criterion(outputs, OUT)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        LOSS = 0.0\n",
        "        if i == 260:    # print every 2000 mini-batches# CHANGE THIS VALUE\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch , i + 1, running_loss / 260))\n",
        "            running_loss = 0.0\n",
        "            \n",
        "            g = 0\n",
        "            for g in range(0,41):\n",
        "                        k=0\n",
        "                        \n",
        "                        for k in range (0,5):\n",
        "                            file_no = random.randint(60000, 72740)\n",
        "                            random_or_counting = random.randint(0, 1)\n",
        "                            dataset_no = random.randint(1, 6)\n",
        "                            if k == 0 :\n",
        "                                    inputs, labels = gen.get_data(file_no,random_or_counting,dataset_no)\n",
        "                            if k > 0 :      \n",
        "                                    inputs_stack, labels_stack = gen.get_data(file_no,random_or_counting,dataset_no)\n",
        "                                    inputs = torch.cat([inputs, inputs_stack])\n",
        "                                    labels = torch.cat([labels, labels_stack])\n",
        " \n",
        "                  \n",
        "\n",
        "                 \n",
        "\n",
        "                 \n",
        "\n",
        "                        INN = inputs.to(device)\n",
        "                        OUT = labels.to(device)\n",
        "           # zero the parameter gradients\n",
        "                        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "                        outputs = net(INN)\n",
        "                        loss = criterion(outputs, OUT)\n",
        "       #    loss = criterion(outputs, labels)\n",
        "                        LOSS  += loss.item()\n",
        "            LOSS = LOSS/40\n",
        "            print('Avergae_validation_loss was='+str(LOSS) )\n",
        "            running_loss = 0.0\n",
        "            if epoch ==1 :\n",
        "                best_loss = LOSS\n",
        "                torch.save(net, '/content/models/'+str('best_loss.pt'))\n",
        "            if LOSS < best_loss:\n",
        "                best_loss = LOSS\n",
        "                torch.save(net, '/content/models/'+str('best_loss.pt'))\n",
        "    \n",
        "            LOSS = 0    \n",
        "            running_loss = 0.0   \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3NL6i9XoUl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/My Drive/FYP data/nyu dataset/TSDF.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RHwmuUCo8rI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/My Drive/FYP data/nyu dataset/ground_truth/train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ptOB5czqrvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##/content/normalized.zip\n",
        "\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/normalized.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}